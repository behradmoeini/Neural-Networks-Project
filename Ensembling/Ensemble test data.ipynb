{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12799, 4)\n"
     ]
    }
   ],
   "source": [
    "# Reading data\n",
    "\n",
    "tweets_xlnet = pd.read_csv('../XLNet/test_with_pred_label_xlnet.csv', encoding=\"utf-8\")\n",
    "tweets_elmo = pd.read_csv('../ELMo/test_with_pred_label_elmo.csv', encoding=\"utf-8\")\n",
    "tweets_bert = pd.read_csv('../BERT/test_with_pred_label_bert.csv', encoding=\"utf-8\")\n",
    "tweets_true_labels = pd.read_csv('../Dataset/test_dataset.csv', encoding=\"utf-8\")\n",
    "\n",
    "#in this project BERT model drops first instance so we have to drop first instance of test data, elmo prediction and xlnet prediction.\n",
    "tweets_true_labels.drop(tweets_true_labels.index[0], inplace=True)\n",
    "tweets_xlnet.drop(tweets_xlnet.index[0], inplace=True)\n",
    "tweets_elmo.drop(tweets_elmo.index[0], inplace=True)\n",
    "\n",
    "xlnet_labels = list(tweets_xlnet['predicted_sentiment'])\n",
    "elmo_labels = list(tweets_elmo['predicted_sentiment'])\n",
    "bert_labels = list(tweets_bert['predicted_sentiment'])\n",
    "true_labels = np.asarray(tweets_true_labels['sentiment'])\n",
    "\n",
    "xlnet_labels_np = np.asanyarray(xlnet_labels)\n",
    "elmo_labels_np = np.asanyarray(elmo_labels)\n",
    "bert_labels_np = np.asanyarray(bert_labels)\n",
    "\n",
    "\n",
    "print(tweets_true_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining one-hot-ecoder and decoder\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(xlnet_labels)\n",
    "\n",
    "def encode(labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def decode(one_hot):\n",
    "    dec = np.argmax(one_hot, axis=1)\n",
    "    return le.inverse_transform(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prioritizing models\n",
    "\n",
    "xlnet_labels_one_hot = encode(xlnet_labels) * 0.55\n",
    "elmo_labels_one_hot = encode(elmo_labels) * 0.6\n",
    "bert_labels_one_hot = encode(bert_labels) * 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensembling\n",
    "\n",
    "ensembled_result = xlnet_labels_one_hot + elmo_labels_one_hot + bert_labels_one_hot\n",
    "temp = np.argmax(ensembled_result, axis=1)\n",
    "ensembled_results = le.inverse_transform(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembled model has accuracy of 65.25% on test data\n"
     ]
    }
   ],
   "source": [
    "# Calculate ensembled accuracy\n",
    "\n",
    "ensembled_test_accuracy = (ensembled_results == true_labels).sum()/ensembled_results.shape[0]\n",
    "print(f\"Ensembled model has accuracy of {round(ensembled_test_accuracy*100,2)}% on test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert model got enhanced -0.23% after ensembling\n",
      "Elmo model got enhanced 5.02% after ensembling\n",
      "Xlnet model got enhanced 11.23% after ensembling\n"
     ]
    }
   ],
   "source": [
    "# Calculate enhancement the accuracy of each models after ensembling\n",
    "import math\n",
    "\n",
    "bert_enhancement_accuracy = ensembled_test_accuracy - ((bert_labels_np == true_labels).sum(axis=0))/ensembled_results.shape[0]\n",
    "print(f\"Bert model got enhanced {round(bert_enhancement_accuracy*100,2)}% after ensembling\")\n",
    "\n",
    "elmo_enhancement_accuracy = ensembled_test_accuracy - ((elmo_labels_np == true_labels).sum(axis=0))/ensembled_results.shape[0]\n",
    "print(f\"Elmo model got enhanced {round(elmo_enhancement_accuracy*100,2)}% after ensembling\")\n",
    "\n",
    "xlnet_enhancement_accuracy = ensembled_test_accuracy - ((xlnet_labels_np == true_labels).sum(axis=0))/ensembled_results.shape[0]\n",
    "print(f\"Xlnet model got enhanced {round(xlnet_enhancement_accuracy*100,2)}% after ensembling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert model labels are 90.96% similar with ensembled model lables\n",
      "Elmo model labels are 73.08% similar with ensembled model lables\n",
      "xlnet model labels are 69.39% similar with ensembled model lables\n"
     ]
    }
   ],
   "source": [
    "# Calculate the similarity between result of seperate models and ensembled model\n",
    "\n",
    "same_in_bert_and_ensembeled = (ensembled_results == bert_labels_np).sum()/ensembled_results.shape[0]\n",
    "print(f\"Bert model labels are {round(same_in_bert_and_ensembeled*100,2)}% similar with ensembled model lables\")\n",
    "\n",
    "same_in_elmo_and_ensembeled = (ensembled_results == elmo_labels_np).sum()/ensembled_results.shape[0]\n",
    "print(f\"Elmo model labels are {round(same_in_elmo_and_ensembeled*100,2)}% similar with ensembled model lables\")\n",
    "\n",
    "same_in_xlnet_and_ensembeled = (ensembled_results == xlnet_labels_np).sum()/ensembled_results.shape[0]\n",
    "print(f\"xlnet model labels are {round(same_in_xlnet_and_ensembeled*100,2)}% similar with ensembled model lables\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
